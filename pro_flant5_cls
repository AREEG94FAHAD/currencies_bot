{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8537038,"sourceType":"datasetVersion","datasetId":5099414}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport random\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-05-29T14:29:50.560187Z","iopub.execute_input":"2024-05-29T14:29:50.561183Z","iopub.status.idle":"2024-05-29T14:29:54.294031Z","shell.execute_reply.started":"2024-05-29T14:29:50.561149Z","shell.execute_reply":"2024-05-29T14:29:54.293111Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import csv\n\n# Assuming your CSV file has 'description' and 'problem_class' as column headers\ndata = []\nwith open('/kaggle/input/newdataset/newDataset.csv', 'r') as csvfile:\n    reader = csv.DictReader(csvfile)\n    for row in reader:\n        data.append((row['text'], row['label']))\n\nx = [d[0] for d in data]\ny = [d[1] for d in data]\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T07:20:54.911788Z","iopub.execute_input":"2024-05-29T07:20:54.912167Z","iopub.status.idle":"2024-05-29T07:20:55.031923Z","shell.execute_reply.started":"2024-05-29T07:20:54.912141Z","shell.execute_reply":"2024-05-29T07:20:55.030921Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"x[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-29T07:20:55.036848Z","iopub.execute_input":"2024-05-29T07:20:55.037122Z","iopub.status.idle":"2024-05-29T07:20:55.043652Z","shell.execute_reply.started":"2024-05-29T07:20:55.037097Z","shell.execute_reply":"2024-05-29T07:20:55.042719Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'Unununium (Uuu) was the name of the chemical\\n    element with atom number 111, until it changed to\\n    Röntgenium (Rg) in 2004. These heavy elements are very\\n    unstable and have only been synthesized in a few\\n    laboratories.\\nYou have just been hired by one of these labs to optimize\\n    the algorithms used in simulations. For example, when\\n    simulating complicated chemical reactions, it is important to\\n    keep track of how many particles there are, and this is done by\\n    counting connected components in a graph.\\nCurrently, the lab has some Python code (see attachments)\\n    that takes an undirected graph and outputs the number of\\n    connected components. As you can see, this code is based on\\n    everyone’s favourite data structure union-find1.\\nAfter looking at the code for a while, you notice that it\\n    actually has a bug in it! The code still gives correct answers,\\n    but the bug could cause it to run inefficiently. Your task is\\n    to construct a graph with a given number of vertices and edges\\n    where the code runs very slowly. We will count how many times\\n    the third line (the one inside the while loop) is visited, and\\n    your program will get a score according to this number.\\n'"},"metadata":{}}]},{"cell_type":"code","source":"def process_phrases(phrases):\n    words = []\n    for phrase in phrases:\n        word = phrase.rstrip('\\n')\n        words.append(word)\n    processed_phrase = ''.join(words)\n    return processed_phrase","metadata":{"execution":{"iopub.status.busy":"2024-05-29T07:20:55.044781Z","iopub.execute_input":"2024-05-29T07:20:55.045145Z","iopub.status.idle":"2024-05-29T07:20:55.051724Z","shell.execute_reply.started":"2024-05-29T07:20:55.045118Z","shell.execute_reply":"2024-05-29T07:20:55.050755Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"x = [process_phrases(nx) for nx in x]\nx[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-29T07:20:55.053221Z","iopub.execute_input":"2024-05-29T07:20:55.053658Z","iopub.status.idle":"2024-05-29T07:20:56.195316Z","shell.execute_reply.started":"2024-05-29T07:20:55.053626Z","shell.execute_reply":"2024-05-29T07:20:56.194424Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'Unununium (Uuu) was the name of the chemical    element with atom number 111, until it changed to    Röntgenium (Rg) in 2004. These heavy elements are very    unstable and have only been synthesized in a few    laboratories.You have just been hired by one of these labs to optimize    the algorithms used in simulations. For example, when    simulating complicated chemical reactions, it is important to    keep track of how many particles there are, and this is done by    counting connected components in a graph.Currently, the lab has some Python code (see attachments)    that takes an undirected graph and outputs the number of    connected components. As you can see, this code is based on    everyone’s favourite data structure union-find1.After looking at the code for a while, you notice that it    actually has a bug in it! The code still gives correct answers,    but the bug could cause it to run inefficiently. Your task is    to construct a graph with a given number of vertices and edges    where the code runs very slowly. We will count how many times    the third line (the one inside the while loop) is visited, and    your program will get a score according to this number.'"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\n\nlabel2id = {\"easy\": 0, \"medium\": 1, \"hard\": 2}\nid2label = {id: label for label, id in label2id.items()}\n\ndef load_dataset(x, y, model_type: str = \"\") -> Dataset:\n    \"\"\"Load dataset.\"\"\"\n    # Create DataFrame from lists x and y\n    dataset_df = pd.DataFrame({\"text\": x, \"label\": y})\n\n    dataset_df[\"label\"] = dataset_df[\"label\"].astype(str)\n#     if model_type == \"AutoModelForSequenceClassification\":\n#         # Convert labels to integers\n#         dataset_df[\"label\"] = dataset_df[\"label\"].map(label2id)\n\n    dataset_df[\"text\"] = dataset_df[\"text\"].astype(str)\n    dataset = Dataset.from_pandas(dataset_df)\n    dataset = dataset.shuffle(seed=42)\n    dataset = dataset.train_test_split(seed = 42, test_size=0.20)\n\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-29T07:20:56.196711Z","iopub.execute_input":"2024-05-29T07:20:56.197131Z","iopub.status.idle":"2024-05-29T07:20:57.969983Z","shell.execute_reply.started":"2024-05-29T07:20:56.197097Z","shell.execute_reply":"2024-05-29T07:20:57.969194Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"dataset = load_dataset(x,y)\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-05-29T07:20:57.971019Z","iopub.execute_input":"2024-05-29T07:20:57.971496Z","iopub.status.idle":"2024-05-29T07:20:58.063999Z","shell.execute_reply.started":"2024-05-29T07:20:57.971470Z","shell.execute_reply":"2024-05-29T07:20:58.063087Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 3289\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 823\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_function(sample: Dataset, padding: str = \"max_length\") -> dict:\n    \"\"\"Preprocess the dataset.\"\"\"\n\n    # add prefix to the input for t5\n    inputs = [\"classify this task as easy, medium, hard: \"+item for item in sample[\"text\"]]\n\n    # tokenize inputs\n    model_inputs = tokenizer(\n        inputs, max_length=max_source_length, padding=padding, truncation=True\n    )\n\n    # Tokenize targets with the `text_target` keyword argument\n    labels = tokenizer(\n        text_target=sample[\"label\"],\n        max_length=max_target_length,\n        padding=padding,\n        truncation=True,\n    )\n\n    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n    # padding in the loss.\n    if padding == \"max_length\":\n        labels[\"input_ids\"] = [\n            [(la if la != tokenizer.pad_token_id else -100) for la in label]\n            for label in labels[\"input_ids\"]\n        ]\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-05-29T07:20:58.065204Z","iopub.execute_input":"2024-05-29T07:20:58.065506Z","iopub.status.idle":"2024-05-29T07:20:58.072595Z","shell.execute_reply.started":"2024-05-29T07:20:58.065480Z","shell.execute_reply":"2024-05-29T07:20:58.071717Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom datasets import Dataset, concatenate_datasets\nfrom transformers import (\n    AutoModelForSeq2SeqLM,\n    AutoTokenizer,\n    DataCollatorForSeq2Seq,\n    Seq2SeqTrainer,\n    Seq2SeqTrainingArguments,\n    T5Tokenizer, T5ForConditionalGeneration\n)\n\nMODEL_ID = \"google/flan-t5-small\"\nmodel = T5ForConditionalGeneration.from_pretrained(MODEL_ID)\ntokenizer = T5Tokenizer.from_pretrained(MODEL_ID)\ntokenizer.model_max_length=1300\n\n\n# Concatenating train and test datasets for tokenization\nconcatenated_dataset = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]])\n\n# # Tokenizing input sequences\ntokenized_inputs = concatenated_dataset.map(\n    lambda x: tokenizer(x[\"text\"], truncation=True),\n    batched=True,\n    remove_columns=[\"text\", \"label\"],\n)\nmax_source_length = max([len(x) for x in tokenized_inputs[\"input_ids\"]])\nprint(f\"Max source length: {max_source_length}\")\n\n# Tokenizing target sequences\ntokenized_targets = concatenated_dataset.map(\n    lambda x: tokenizer(x[\"label\"], truncation=True),\n    batched=True,\n    remove_columns=[\"text\", \"label\"],\n)\nmax_target_length = max([len(x) for x in tokenized_targets[\"input_ids\"]])\nprint(f\"Max target length: {max_target_length}\")\n\ntokenized_dataset = dataset.map(\n    preprocess_function, batched=True, remove_columns=[\"text\", \"label\"]\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T07:20:58.075564Z","iopub.execute_input":"2024-05-29T07:20:58.075864Z","iopub.status.idle":"2024-05-29T07:21:32.118483Z","shell.execute_reply.started":"2024-05-29T07:20:58.075832Z","shell.execute_reply":"2024-05-29T07:21:32.117487Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2024-05-29 07:21:01.522871: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-29 07:21:01.522977: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-29 07:21:01.654772: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aef9f07836124c289e99fda316a1e13f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2a8893e63bd42fa8d8be3953ecb8954"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92c5f819d6434bf4ac0f15f067534514"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23b010a3d6604a559b6456190fcf22a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"443de45f8a824562a759e05a68ea5a98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e791d3f09b94fc88d543a5073c89a9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c3d19e3edca4d33bcc9b22096fbef61"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4112 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f00abf63b06433e89dab13829f87396"}},"metadata":{}},{"name":"stdout","text":"Max source length: 1300\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4112 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48541a02a04c461a9800f3921f58136a"}},"metadata":{}},{"name":"stdout","text":"Max target length: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3289 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ee44785af6944ea82bddd5187746439"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/823 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93e599ef67d14d479332f6c94ca9dd2e"}},"metadata":{}}]},{"cell_type":"code","source":"# Define training args\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir='output',\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    predict_with_generate=True,\n    fp16=False,\n    learning_rate=5e-4,\n    num_train_epochs=50,\n    logging_dir=\"output/logs\",  \n    logging_strategy=\"epoch\",\n    evaluation_strategy=\"no\",\n    save_strategy=\"epoch\",\n    save_total_limit=5,\n    load_best_model_at_end=False,\n    report_to=\"tensorboard\",\n\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T07:21:32.119639Z","iopub.execute_input":"2024-05-29T07:21:32.120191Z","iopub.status.idle":"2024-05-29T07:21:32.190130Z","shell.execute_reply.started":"2024-05-29T07:21:32.120164Z","shell.execute_reply":"2024-05-29T07:21:32.189375Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset = dataset.map(\n    preprocess_function, batched=True, remove_columns=[\"text\", \"label\"]\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T07:21:32.191187Z","iopub.execute_input":"2024-05-29T07:21:32.191485Z","iopub.status.idle":"2024-05-29T07:21:41.367054Z","shell.execute_reply.started":"2024-05-29T07:21:32.191459Z","shell.execute_reply":"2024-05-29T07:21:41.366133Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3289 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba78983ee3ea4cf1a68f5b06c6b61f30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/823 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6124e06c31754e58bd659961baf00aea"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-29T07:21:41.368232Z","iopub.execute_input":"2024-05-29T07:21:41.368529Z","iopub.status.idle":"2024-05-29T07:21:41.374519Z","shell.execute_reply.started":"2024-05-29T07:21:41.368503Z","shell.execute_reply":"2024-05-29T07:21:41.373539Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 3289\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 823\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_dataset['train'][0]['labels']","metadata":{"execution":{"iopub.status.busy":"2024-05-29T07:21:41.375842Z","iopub.execute_input":"2024-05-29T07:21:41.376114Z","iopub.status.idle":"2024-05-29T07:21:41.388903Z","shell.execute_reply.started":"2024-05-29T07:21:41.376080Z","shell.execute_reply":"2024-05-29T07:21:41.388041Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"[614, 1]"},"metadata":{}}]},{"cell_type":"code","source":"label_pad_token_id = -100\n    # Data collator\ndata_collator = DataCollatorForSeq2Seq(\n        tokenizer,\n        model=model,\n        label_pad_token_id=label_pad_token_id,\n        pad_to_multiple_of=8,\n    )\n\n    # Create Trainer instance\ntrainer = Seq2SeqTrainer(\n        model=model,\n        args=training_args,\n        data_collator=data_collator,\n        train_dataset=tokenized_dataset[\"train\"],\n        eval_dataset=tokenized_dataset[\"test\"],\n    )\n\n# TRAIN\ntrainer.train()\n# trainer.evaluate()\n# SAVE\ntokenizer.save_pretrained('output')","metadata":{"execution":{"iopub.status.busy":"2024-05-29T07:21:41.390051Z","iopub.execute_input":"2024-05-29T07:21:41.390403Z","iopub.status.idle":"2024-05-29T10:35:07.267821Z","shell.execute_reply.started":"2024-05-29T07:21:41.390352Z","shell.execute_reply":"2024-05-29T10:35:07.266851Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='20600' max='20600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [20600/20600 3:13:23, Epoch 50/50]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>412</td>\n      <td>0.612900</td>\n    </tr>\n    <tr>\n      <td>824</td>\n      <td>0.499300</td>\n    </tr>\n    <tr>\n      <td>1236</td>\n      <td>0.461800</td>\n    </tr>\n    <tr>\n      <td>1648</td>\n      <td>0.378300</td>\n    </tr>\n    <tr>\n      <td>2060</td>\n      <td>0.289900</td>\n    </tr>\n    <tr>\n      <td>2472</td>\n      <td>0.228300</td>\n    </tr>\n    <tr>\n      <td>2884</td>\n      <td>0.163400</td>\n    </tr>\n    <tr>\n      <td>3296</td>\n      <td>0.128100</td>\n    </tr>\n    <tr>\n      <td>3708</td>\n      <td>0.122400</td>\n    </tr>\n    <tr>\n      <td>4120</td>\n      <td>0.103400</td>\n    </tr>\n    <tr>\n      <td>4532</td>\n      <td>0.086200</td>\n    </tr>\n    <tr>\n      <td>4944</td>\n      <td>0.073600</td>\n    </tr>\n    <tr>\n      <td>5356</td>\n      <td>0.075100</td>\n    </tr>\n    <tr>\n      <td>5768</td>\n      <td>0.068800</td>\n    </tr>\n    <tr>\n      <td>6180</td>\n      <td>0.075900</td>\n    </tr>\n    <tr>\n      <td>6592</td>\n      <td>0.052500</td>\n    </tr>\n    <tr>\n      <td>7004</td>\n      <td>0.053900</td>\n    </tr>\n    <tr>\n      <td>7416</td>\n      <td>0.049700</td>\n    </tr>\n    <tr>\n      <td>7828</td>\n      <td>0.044600</td>\n    </tr>\n    <tr>\n      <td>8240</td>\n      <td>0.049500</td>\n    </tr>\n    <tr>\n      <td>8652</td>\n      <td>0.040900</td>\n    </tr>\n    <tr>\n      <td>9064</td>\n      <td>0.038500</td>\n    </tr>\n    <tr>\n      <td>9476</td>\n      <td>0.035600</td>\n    </tr>\n    <tr>\n      <td>9888</td>\n      <td>0.030100</td>\n    </tr>\n    <tr>\n      <td>10300</td>\n      <td>0.023500</td>\n    </tr>\n    <tr>\n      <td>10712</td>\n      <td>0.021600</td>\n    </tr>\n    <tr>\n      <td>11124</td>\n      <td>0.031100</td>\n    </tr>\n    <tr>\n      <td>11536</td>\n      <td>0.036700</td>\n    </tr>\n    <tr>\n      <td>11948</td>\n      <td>0.027300</td>\n    </tr>\n    <tr>\n      <td>12360</td>\n      <td>0.020500</td>\n    </tr>\n    <tr>\n      <td>12772</td>\n      <td>0.031800</td>\n    </tr>\n    <tr>\n      <td>13184</td>\n      <td>0.022100</td>\n    </tr>\n    <tr>\n      <td>13596</td>\n      <td>0.019600</td>\n    </tr>\n    <tr>\n      <td>14008</td>\n      <td>0.019200</td>\n    </tr>\n    <tr>\n      <td>14420</td>\n      <td>0.021300</td>\n    </tr>\n    <tr>\n      <td>14832</td>\n      <td>0.019400</td>\n    </tr>\n    <tr>\n      <td>15244</td>\n      <td>0.021500</td>\n    </tr>\n    <tr>\n      <td>15656</td>\n      <td>0.020200</td>\n    </tr>\n    <tr>\n      <td>16068</td>\n      <td>0.015700</td>\n    </tr>\n    <tr>\n      <td>16480</td>\n      <td>0.017500</td>\n    </tr>\n    <tr>\n      <td>16892</td>\n      <td>0.014600</td>\n    </tr>\n    <tr>\n      <td>17304</td>\n      <td>0.019000</td>\n    </tr>\n    <tr>\n      <td>17716</td>\n      <td>0.016400</td>\n    </tr>\n    <tr>\n      <td>18128</td>\n      <td>0.014800</td>\n    </tr>\n    <tr>\n      <td>18540</td>\n      <td>0.014500</td>\n    </tr>\n    <tr>\n      <td>18952</td>\n      <td>0.015700</td>\n    </tr>\n    <tr>\n      <td>19364</td>\n      <td>0.014200</td>\n    </tr>\n    <tr>\n      <td>19776</td>\n      <td>0.012600</td>\n    </tr>\n    <tr>\n      <td>20188</td>\n      <td>0.012100</td>\n    </tr>\n    <tr>\n      <td>20600</td>\n      <td>0.012000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"('output/tokenizer_config.json',\n 'output/special_tokens_map.json',\n 'output/spiece.model',\n 'output/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"model_name = \"/kaggle/working/output/checkpoint-19776\"\nfine_tuning = AutoModelForSeq2SeqLM.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T10:39:11.170007Z","iopub.execute_input":"2024-05-29T10:39:11.170695Z","iopub.status.idle":"2024-05-29T10:39:11.662919Z","shell.execute_reply.started":"2024-05-29T10:39:11.170660Z","shell.execute_reply":"2024-05-29T10:39:11.662139Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"import torch\n\nresults = []\n# Assuming you have a CUDA device available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# tokenizer\nfine_tuning.to(device)\n\nfor i in range(len(dataset['test'])):\n    inputs = tokenizer(\"classify this task as easy, medium, hard: \"+dataset['test'][i]['text'], return_tensors='pt')\n\n    # Move input tensors to the chosen device\n    inputs = inputs.to(device)\n\n    output = tokenizer.decode(\n        fine_tuning.generate(\n            inputs[\"input_ids\"],\n            max_new_tokens=10\n        )[0],\n        skip_special_tokens=True\n    )\n#     print(output)\n    results.append(output)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T10:39:12.538300Z","iopub.execute_input":"2024-05-29T10:39:12.539214Z","iopub.status.idle":"2024-05-29T10:39:43.169713Z","shell.execute_reply.started":"2024-05-29T10:39:12.539177Z","shell.execute_reply":"2024-05-29T10:39:43.168900Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# listresults = dataa['test']['label']\nmatch_count =0\nfor i in range(len(results)):\n    if results[i] == dataset['test'][i]['label']:\n        match_count += 1\n\nprint(f\"Number of matching values: {match_count/823}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-29T10:39:43.171316Z","iopub.execute_input":"2024-05-29T10:39:43.171627Z","iopub.status.idle":"2024-05-29T10:39:43.243003Z","shell.execute_reply.started":"2024-05-29T10:39:43.171602Z","shell.execute_reply":"2024-05-29T10:39:43.242138Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Number of matching values: 0.5224787363304981\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n\n# Define your lists\ny_true = dataset['test']['label'] # Example true labels\ny_pred = results  # Example predicted labels\n\n# Compute precision, recall, and F1 score\nprecision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=None, labels=['easy', 'medium', 'hard'])\n\n# Compute confusion matrix\ncm = confusion_matrix(y_true, y_pred, labels=['easy', 'medium', 'hard'])\n\n# Print the results\nprint(\"Precision: \", precision)\nprint(\"Recall: \", recall)\nprint(\"F1 Score: \", f1)\nprint(\"Confusion Matrix:\\n\", cm)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T10:39:43.243988Z","iopub.execute_input":"2024-05-29T10:39:43.244231Z","iopub.status.idle":"2024-05-29T10:39:43.269908Z","shell.execute_reply.started":"2024-05-29T10:39:43.244208Z","shell.execute_reply":"2024-05-29T10:39:43.268992Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Precision:  [0.5        0.40112994 0.56949807]\nRecall:  [0.41558442 0.26394052 0.7375    ]\nF1 Score:  [0.45390071 0.31838565 0.64270153]\nConfusion Matrix:\n [[ 64  38  52]\n [ 27  71 171]\n [ 37  68 295]]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}